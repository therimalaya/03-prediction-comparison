# Experimental Design #

This study compares prediction methods based on their prediction ability. Data with specific properties are simulated, some of which are easier to predict than others. These data are simulated using the R-package `simrel`, which is discussed in @saebo2015simrel and @Rimal2018. Here we have used four different factors to vary the property of the data: a) Number of predictors (`p`), b) Multicollinearity in predictor variables (`gamma`), c) Correlation in response variables (`eta`) and d) position of predictor components relevant for the response (`relpos`). Using two levels of `p`, `gamma` and `relpos` and four levels of `eta`, `r nrow(design)` set of distinct properties are designed for the simulation.

__Number of predictors:__
: To observe the performance of the methods on tall and wide predictor matrices, `r catvec(opts$p)` predictor variables are simulated with the number of observations fixed at 100. Parameter `p` controls these properties in the `simrel` function.

__Multicollinearity in predictor variables:__
: Highly collinear predictors can be explained completely by few components. The parameter `gamma` ($\gamma$) in `simrel` controls decline in the eigenvalues of the predictor variables as \@ref(eq:gamma).

    \begin{equation}
      \lambda_i = e^{-\gamma(i - 1)}, \gamma > 0 \text{ and } i = 1, 2, \ldots, p
      (\#eq:gamma)
    \end{equation}

  Here, $\lambda_i, i = 1, 2, \ldots p$ are eigenvalues of the predictor variables. We have used `r catvec(opts$gamma)` as different levels of `gamma`. The higher the value of gamma, the higher the multicollinearity will be, and vice versa.

__Correlation in response variables:__
: Correlation among response variables has been explored to a lesser extent. Here we have tried to explore that part with `r num_vec[length(opts$eta)]` levels of correlation in the response variables. We have used the `eta` ($\eta$) parameter of `simrel` for controlling the decline in eigenvalues corresponding to the response variables as \@ref(eq:eta).

    \begin{equation}
      \kappa_j = e^{-\eta(j - 1)}, \eta > 0 \text{ and } j = 1, 2, \ldots, m
      (\#eq:eta)
    \end{equation}

  Here, $\kappa_j, i = 1, 2, \ldots m$ are the eigenvalues of the response variables and `m` is the number of response variables. We have used `r catvec(opts$eta)` as different levels of `eta`. The larger the value of eta, the larger will be the correlation will be between response variables, and vice versa.

__Position of predictor components relevant to the response:__
: The principal components of the predictors are ordered. The first principal component captures most of the variation in the predictors. The second captures the most of the remainder left by the first principal component and so on. In highly collinear predictors, the variation captured by the first few components is relatively high. However, if those components are not relevant for the response, prediction becomes difficult [@Helland1994b]. Here, two levels of the positions of these relevant components are used as `r catvec(sapply(opts$relpos, list2chr))`.


Moreover, a complete factorial design from the levels of the above parameters gave us `r nrow(design)` designs. Each design is associated with a dataset having unique properties. Figure~\@ref(fig:design-plot), shows all the designs. For each design and prediction method, 50 datasets were simulated as replicates. In total, there were $`r length(mthds)` \times `r nrow(design)` \times 50$, i.e. `r length(mthds) * nrow(design) * 50` simulated datasets.

```{r design-plot, fig.cap="Experimental Design of simulation parameters. Each point represents a unique data property.", echo = FALSE, fig.asp=0.5, fig.width=8}
design_chr %>%
    mutate(Design = row_number()) %>%
    ggplot(aes(eta, gamma)) +
    geom_point(shape=4) +
    ggrepel::geom_text_repel(aes(label = Design), nudge_x = 0.03) +
    facet_grid(p ~ relpos, labeller=label_both) +
    scale_y_reverse(breaks = opts$gamma) +
    scale_x_continuous(breaks = opts$eta) +
    theme_minimal(base_size=16) +
    theme(text=element_text(family="mono")) +
    coord_fixed(ratio=0.5)
```


__Common parameters:__
: Each dataset was simulated with $n = `r unique(opts$n)`$ number of observation and $m = `r unique(opts$m)`$ response variables. Furthermore, the coefficient of determination corresponding to each response components in all the designs is set to `r unique(opts$R2)`. In addition, we have assumed that there is only `r num_vec[length(unique(design$ypos)[[1]])]` informative response component. Hence, the informative response component is rotated orthogonally together with `r num_vec[unique(opts$m) - length(unique(design$ypos)[[1]])]` uninformative response components to generate `r num_vec[unique(opts$m)]` response variables. This spreads out the information in all simulated response variables. For further details on the simulation tool, see [@Rimal2018].

An example of simulation parameters for the first design is as follows:

```{r sample_design, echo = TRUE, eval = FALSE}
simrel(
    n       = 100,                 ## Training samples
    p       = 20,                  ## Predictors
    m       = 4,                   ## Responses
    q       = 20,                  ## Relevant predictors
    relpos  = list(c(1, 2, 3, 4)), ## Relevant predictor components index
    eta     = 0,                   ## Decay factor of response eigenvalues
    gamma   = 0.2,                 ## Decay factor of predictor eigenvalues
    R2      = 0.8,                 ## Coefficient of determination
    ypos    = list(c(1, 2, 3, 4)),
    type    = "multivariate"
)
```


```{r cov-plot-1, fig.width = 9, out.width = "100%", fig.asp = 0.5, fig.cap="(left) Covariance structure of latent components (right) Covariance structure of predictor and response", message=FALSE, eval=TRUE}
set.seed(010101)
sobj <- design %>%
    get_design(1) %>%
    simulate()
plt1 <- cov_plot(sobj, type = "relpos", facetting = FALSE) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5),
          panel.grid.minor = element_line(size = 0.2),
          panel.grid.major = element_blank())
plt2 <- cov_plot(sobj, type = "relpred", facetting = FALSE) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5),
          panel.grid.minor = element_line(size = 0.2),
          panel.grid.major = element_blank()) +
    scale_fill_brewer(palette = 'Set1',
                      labels = paste0("Y", unlist(sobj$ypos), collapse = ", "))
plt <- gridExtra::arrangeGrob(plt1, plt2, nrow = 1)
grid::grid.newpage()
grid::grid.draw(plt)
```



 The covariance structure of the data simulated with this design in the Figure \@ref(fig:cov-plot-1) shows that the predictor components at positions `r catvec(unlist(sobj$relpos))` are relevant for the first response component. After the rotation with orthogonal rotation matrix, all predictor variables are somewhat relevant for all response variables, satisfying other desired properties such as multicollinearity and coefficient of determination. For the same design, Figure \@ref(fig:est-cov-plot) (top left) shows that the predictor components `r catvec(unlist(sobj$relpos))` are relevant for the first response component. All other predictor components are irrelevant and all other response components are uninformative. However, due to orthogonal rotation of the informative response component together with uninformative response components, all response variables in the population have similar covariance with the relevant predictor components (Figure \@ref(fig:est-cov-plot) (top right)). The sample covariances between the predictor components and predictor variables with response variables are shown in Figure \@ref(fig:est-cov-plot) (bottom left) and (bottom right) respectively.


(ref:simrel-plot) Expected Scaled absolute covariance between predictor components and response components (top left). Expected Scaled absolute covariance between predictor components and response variables (top right). Sample scaled absolute covariance between predictor components and response variables (bottom left). Sample scaled absolute covariance between predictor variables and response variables (bottom right). The bar graph in the background represents eigenvalues corresponding to each components in population (top plots) and in sample (bottom plots). One can compare the top-right plot (true covariance of the population) with bottom-left (covariance in the simulated data) which shows a similar pattern for different components.

```{r est-cov-plot, fig.asp = 0.8, fig.width = 9, fig.cap = "(ref:simrel-plot)", warnings=FALSE, message=FALSE}
set.seed(010101) # design-method-replication
sobj <- design %>%
  get_design(1) %>%
  simulate()
breakx <- function(x) floor(seq(min(x), max(x), 2))
title_common <- function(title) {
  ggtitle(NULL, title)
}
thm_common <- theme(
  legend.position = c(0.99, 0.99),
  legend.direction = "horizontal",
  legend.justification = c(1, 1))
guid_common <- guides(color = guide_legend(title.position = "top"))
labs_common <- labs(y = NULL)
plt1 <- ggsimrelplot(sobj, which = 2, use_population = TRUE) +
  thm_common + guid_common + labs_common +
  title_common("Between predictor components and response components.") +
  scale_x_continuous(breaks = breakx)
plt2 <- ggsimrelplot(sobj, which = 3, use_population = TRUE) +
  thm_common + guid_common + labs_common +
  title_common("Between predictor components and response variables.") +
  scale_x_continuous(breaks = breakx)
plt3 <- ggsimrelplot(sobj, which = 3, use_population = FALSE) +
  title_common("Between predictor components and response variables.") +
  scale_x_continuous(breaks = breakx) +
  thm_common + guid_common + labs_common
plt4 <- ggsimrelplot(sobj, which = 4, use_population = FALSE) +
  title_common("Between predictor variables and response variables.") +
  scale_x_continuous(breaks = breakx) +
  thm_common + guid_common + labs_common
plt12 <- gridExtra::arrangeGrob(
  plt1, plt2, ncol = 2,
  top = "Scaled absolute population covariance")
plt34 <- gridExtra::arrangeGrob(
  plt3, plt4, ncol = 2,
  top = "Scaled absolute sample covariance"
)
plt <- gridExtra::arrangeGrob(plt12, plt34, ncol = 1, left = "Absolute Scaled Covariance")
grid::grid.newpage()
grid::grid.draw(plt)
```


A similar description can be made for all 32 designs, where each of the designs holds the properties of the data they simulate. These data are used by the prediction methods discussed in the previous section. Each prediction method is given independently simulated datasets in order to give them an equal opportunity to capture the dynamics in the data.

# Basis of comparison

This study focuses mainly on the prediction performance of the methods with emphasis specifically on the interaction between the properties of the data controlled by the simulation parameters, and the prediction methods. The prediction performance is measured based on the following:

a) The average prediction error that a method can give using arbitrary number of components and
b) The average number of components used by the method to give the minimum prediction error

Let us define,

\begin{equation}
\mathcal{PE}_{ijkl} = \frac{1}{\sigma_{y_{ij}|x}^2}
  \mathsf{E}{\left[\left(\boldsymbol{\beta}_{ij} -
  \boldsymbol{\hat{\beta}_{ijkl}}\right)^t
  \left(\boldsymbol{\Sigma}_{xx}\right)_i
  \left(\boldsymbol{\beta}_{ij} - \boldsymbol{\hat{\beta}_{ijkl}}\right)\right]} + 1
(\#eq:pred-error)
\end{equation}
as a prediction error of response $j = 1, \ldots 4$ for a given design $i=1, 2, \ldots 32$ and method $k=1(\text{PCR}), \ldots 5(\text{Senv})$ using $l=0, \ldots 10$ number of components. Here, $\left(\boldsymbol{\Sigma}_{xx}\right)_i$ is the true covariance matrix of the predictors, unique for a particular design $i$ and $\sigma_{y_j\mid x}^2$ for response $j = 1, \ldots m$ is the true model error. Here prediction error is scaled by the true model error to remove the effects of influencing residual variances. Since both the expectation and the variance of $\hat{\boldsymbol{\beta}}$ are unknown, the prediction error is estimated using data from 50 replications as follows,

\begin{equation}
\widehat{\mathcal{PE}_{ijkl}} = \frac{1}{\sigma_{y_{ij}|x}^2}
  \sum_{r=0}^{50}{\left[\left(\boldsymbol{\beta}_{ij} -
  \boldsymbol{\hat{\beta}_{ijklr}}\right)^t
  \left(\boldsymbol{\Sigma}_{xx}\right)_i
  \left(\boldsymbol{\beta}_{ij} - \boldsymbol{\hat{\beta}_{ijklr}}\right)\right]} + 1
(\#eq:estimated-pred-error)
\end{equation}
where $\widehat{\mathcal{PE}_{ijkl}}$ is the estimated prediction error averaged over $r=50$ replicates.

The following section focuses on the data for the estimation of these prediction errors that are used for the two models discussed above in a) and b) of this section.

# Data Preparation

A dataset for estimating \@ref(eq:pred-error) is obtained from simulation which contains a) five factors corresponding to simulation parameters, b) prediction methods, c) number of components, d) replications and e) prediction error for `r num_vec[unique(opts$m)]` responses. The prediction error is computed using predictor components ranging from 0 to 10 for each 50 replicates as,

\begin{equation*}
\left(\widehat{\mathcal{PE_\circ}}\right)_{ijklr} =
  \frac{1}{\sigma_{y_{ij}\mid x}^2}\left[
    \left(\boldsymbol{\beta}_{ij} - \hat{\boldsymbol{\beta}}_{ijklr}\right)^t
    \left(\boldsymbol{\Sigma}_{xx}\right)_{i}
    \left(\boldsymbol{\beta}_{ij} - \hat{\boldsymbol{\beta}}_{ijklr}\right)
  \right] + 1
\end{equation*}

Thus there are `r nrow(design)` (designs) $\times$ `r length(mthds)` (methods) $\times$ 11 (number of components) $\times$ 50 (replications), i.e. `r nrow(design) * length(mthds) * 11 * 50` observations corresponding to the response variables from `Y1` to `Y4`.

```{r data-prep}
pred_dta <- design_chr %>%
  select_if(function(x) n_distinct(x) > 1) %>%
  mutate(Design = as.character(1:n())) %>%
  mutate_at(vars(p, gamma, relpos, eta), as.factor) %>%
  right_join(pred_error, by = "Design") %>%
  mutate_if(is.character, as.factor) %>%
  mutate_at("p", as.factor) %>%
  mutate(Response = paste0("Y", Response))
pred_spread_df <- pred_dta %>%
  as.data.frame() %>%
  select(-Design, -q) %>%
  spread(Response, Pred_Error)
min_comp_stk <- pred_dta %>%
  group_by(p, relpos, eta, gamma, Method, Tuning_Param, Response) %>%
  summarize(Pred_Error = mean(Pred_Error)) %>%
  group_by(p, relpos, eta, gamma, Method, Response) %>%
  summarize(Tuning_Param = Tuning_Param[which.min(Pred_Error)])
pred_min <- pred_dta %>%
  select(-Design, -q) %>%
  semi_join(min_comp_stk, by = c(
    "p", "relpos", "eta", "gamma", "Method",
    "Tuning_Param", "Response"
  )) %>% select(-Tuning_Param) %>%
  spread(Response, Pred_Error)
comp_min <- pred_dta %>%
  group_by(p, relpos, eta, gamma, Method, Replication, Response) %>%
  summarize(Tuning_Param = Tuning_Param[which.min(Pred_Error)]) %>%
  spread(Response, Tuning_Param)
```

Since our discussions focus on the average minimum prediction error that a method can obtain and the average number of components they use to get the minimum prediction error in each replicates, the dataset discussed above is summarized as constructing the following two smaller datasets. Let us call them _Error Dataset_ and _Component Dataset_.

_Error Dataset_:
: For each prediction method, design and response, an average prediction error is computed over all replicates for each component. Next, a component that gives the minimum of this average prediction error is selected, i.e.,
  \begin{equation}
  l_\circ = \operatorname*{argmin}_{l}\left[\frac{1}{50}\sum_{i=1}^{50}{\left(\mathcal{PE}_\circ\right)_{ijklr}}\right]
  (\#eq:min-pred)
  \end{equation}

: Using the component $l_\circ$, a dataset of
$\left(\mathcal{PE}_\circ\right)_{ijkl_\circ r}$ is used as the _Error Dataset_.
Let $\mathbf{u}_{(`r nrow(pred_min)` \times 4)} = (u_j)$ for $j = 1, \ldots 4$ be the outcome variables measuring the prediction error corresponding to the response number $j$ in the context of this dataset.

_Component Dataset_:
: The number of components that gives the minimum prediction error in each replication is referred to as the _Component Dataset_, i.e.,
  \begin{equation}
  l_{\circ} = \operatorname*{argmin}_{l}\left[\mathcal{PE}_{ijklr}\right]
  (\#eq:min-comp)
  \end{equation}
  Here $l_\circ$ is the number of components that gives minimum prediction error $\left(\mathcal{PE}_\circ\right)_{ijklr}$ for design $i$, response $j$, method $k$ and replicate $r$. Let $\mathbf{v}_{(`r nrow(comp_min)` \times 4)} = (v_j)$ for $j = 1, \ldots 4$ be the outcome variables measuring the number of components used for minimum prediction error corresponding to the response $j$ in the context of this dataset.
