# Statistical Analysis
This section has modelled the _error data_ and the _component data_ as a function of the simulation parameters to better understand the connection between data properties and prediction methods using multivariate analysis of variation (MANOVA).

```{r knitr_setup}
options(knitr.kable.NA = '')
docs_format <- ifelse(knitr::is_latex_output(), "latex", "html")
print_manova <- function(tbl, format = docs_format, level = 0.05, ...){
  signif_idx <- which(tbl[, ncol(tbl)] <= level)
  knitr::kable(
    x = tbl, digits = 3, booktabs = TRUE,
    longtable = TRUE, format = format,
    escape = FALSE, linesep = "", ...) %>%
    kableExtra::kable_styling(latex_options = c("repeat_header")) %>%
    kableExtra::column_spec(1:7, monospace = TRUE) %>%
    kableExtra::row_spec(signif_idx, color = "red")
}
```

Let us consider a model with third order interaction of the simulation parameters (`p`, `gamma`, `eta` and `relpos`) and `Methods` as in \@ref(eq:error-model) and \@ref(eq:component-model) using datasets $\mathbf{u}$ and $\mathbf{v}$, respectively. Let us refer them as the _error model_ and the _component model_.

**Error Model:**
: \begin{equation}\mathbf{u}_{abcdef} = \boldsymbol{\mu}_u +
  (\texttt{p}_a + \texttt{gamma}_b + \texttt{eta}_c +
    \texttt{relpos}_d + \texttt{Methods}_e)^3 +
  \left(\boldsymbol{\varepsilon}_u\right)_{abcdef}
  (\#eq:error-model)
  \end{equation}

**Component Model:**
: \begin{equation}\mathbf{v}_{abcdef} = \boldsymbol{\mu}_v +
  (\texttt{p}_a + \texttt{gamma}_b + \texttt{eta}_c +
    \texttt{relpos}_d + \texttt{Methods}_e)^3 +
  \left(\boldsymbol{\varepsilon}_v\right)_{abcdef}
  (\#eq:component-model)
  \end{equation}

where, $\mathbf{u}_{abcdef}$ is a vector of prediction errors in the _error model_ and $\mathbf{v}_{abcdef}$ is a vector of the number of components used by a method to obtain minimum prediction error in the _component model_.

Although there are several test-statistics for MANOVA, all are essentially equivalent for large samples [@johnson2018applied]. Here we will use Pillai's trace statistic which is defined as,

\begin{equation}
\text{Pillai statistic} = \text{tr}\left[
\left(\mathbf{E} + \mathbf{H}\right)^{-1}\mathbf{H}
\right] = \sum_{i=1}^m{\frac{\nu_i}{1 + \nu_i}}
(\#eq:pillai)
\end{equation}
Here the matrix $\mathbf{H}$ holds between-sum-of-squares and sum-of-products for each of the predictors. The matrix $\mathbf{E}$ has a within the sum of squares and sum of products for each of the predictors. $\nu_i$ represents the eigenvalues corresponding to $\mathbf{E}^{-1}\mathbf{H}$ [@rencher2003methods].

For both the models \@ref(eq:error-model) and \@ref(eq:component-model), Pillai's trace statistic is used for accessing the effect of each factor and returns an F-value for the strength of their significance. Figure \@ref(fig:manova-plot) plots the Pillai's trace statistics as bars with corresponding F-values as text labels for both models.

```{r manova-model}
pred_mdl <- lm(
  formula = cbind(Y1, Y2, Y3, Y4) ~ (p + gamma + eta + relpos + Method) ^ 3,
  data = pred_min)
comp_mdl <- lm(
  formula = cbind(Y1, Y2, Y3, Y4) ~ (p + gamma + eta + relpos + Method) ^ 3,
  data = comp_min)
```

```{r manova-summary}
pred_aov <- anova(pred_mdl) %>%
  as_tibble(rownames = "Factors")
comp_aov <- anova(comp_mdl) %>%
  as_tibble(rownames = "Factors")
aov_df <- bind_rows(list(Pred = pred_aov, Comp = comp_aov), .id = "Type")
```

(ref:manova-plot) Pillai Statistic and F-value for the MANOVA model. The bar represents the Pillai Statistic and the text labels are F-value for the corresponding factor.


```{r manova-plot-old, fig.width=8, out.width='100%', fig.asp=0.5, fig.cap="(ref:manova-plot)", eval=FALSE}
model_labels <- c(
  Comp = "Model: Number of Components",
  Pred = "Model: Prediction Error"
)
aov_df %>%
  filter(!(Factors %in% c('Residuals', '(Intercept)'))) %>%
  select(Model = Type, Factors, Pillai,
         Fvalue = `approx F`, Pvalue = `Pr(>F)`) %>%
  mutate(Model = factor(Model, levels = c("Pred", "Comp"))) %>%
  mutate(Pvalue = ifelse(Pvalue < 0.05, "<0.05", ">=0.05")) %>%
  ggplot(aes(reorder(Factors, log1p(Fvalue)),
             log1p(Fvalue), fill = Pvalue)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = round(Pillai, 2)), family = 'mono',
            angle = 90, hjust = "inward") +
  facet_grid(cols = vars(Model), scales = 'free_y',
             labeller = labeller(Model = model_labels)) +
  theme_grey(base_family = "mono") +
  theme(legend.position = c(0.2, 0.9),
        legend.direction = 'horizontal',
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(x = NULL, y = "log1p(Fvalue)") +
  scale_y_continuous(trans = "log1p", breaks = scales::pretty_breaks(n=6))
```

```{r manova-plot, fig.width=8, out.width='100%', fig.asp=0.8, fig.cap="(ref:manova-plot)"}
model_labels <- c(
  Comp = "Model: Number of Components",
  Pred = "Model: Prediction Error"
)
aov_df %>%
    filter(!(Factors %in% c('Residuals', '(Intercept)'))) %>%
    select(Model = Type, Factors, Pillai,
           Fvalue = `approx F`, Pvalue = `Pr(>F)`) %>%
    mutate(Model = factor(Model, levels = c("Pred", "Comp"))) %>%
    mutate(Pvalue = ifelse(Pvalue < 0.05, "<0.05", ">=0.05")) %>%
    ggplot(aes(reorder(Factors, Pillai), Pillai, fill = Pvalue)) +
    geom_bar(stat = "identity") +
    geom_text(aes(label = round(Fvalue, 2)), family = 'mono',
              angle = 0, hjust = "inward", size = 3) +
    facet_grid(cols = vars(Model), scales = 'free_y',
               labeller = labeller(Model = model_labels)) +
    theme_grey(base_family = "mono") +
    theme(legend.position = c(0.85, 0.1),
          legend.direction = 'horizontal',
          axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
    guides(fill = guide_legend(title.position = "top",
                               title.hjust = 0.5)) +
    labs(x = NULL, y = "Pillai Statistic") +
    coord_flip()
```

Error Model:
: Figure \@ref(fig:manova-plot) (left) shows the Pillai's trace statistic for factors of the _error model_. The main effect of `Method` followed by `relpos`, `eta` and `gamma` have largest influence on the model. A highly significant two-factor interaction of `Method` with `gamma` followed by `relpos` and `eta` clearly shows that methods perform differently for different levels of these data properties. The significant third order interaction between `Method`, `eta` and `gamma` suggests that the performance of a method differs for a given level of multicollinearity and the correlation between the responses. Since only some methods consider modelling predictor and response together, the prediction is affected by the level of correlation between the responses (`eta`) for a given method.

Component Model:
: Figure \@ref(fig:manova-plot) (right) shows the Pillai's trace statistic for factors of the _component model_. As in the _error model_, the main effects of the Method, `relpos`, `gamma` and `eta` have a significantly large effect on the number of components that a method has used to obtain minimum prediction error. The two-factor interactions of `Method` with simulation parameters are larger in this case. This shows that the Methods and these interactions have a larger effect on the use of the number of component than the prediction error itself. In addition, a similar significant high third-order interaction as found in the _error model_ is also observed in this model.


The following section will continue to explore the effects of different levels of the factors in the case of these interactions.

## Effect Analysis of Error Model

The large difference in the prediction error for the envelope models in Figure \@ref(fig:pred-eff-plots) (left) is intensified when the position of the relevant predictor is at `r unique(opts$relpos)[2]`. The results also show that the envelope methods are more sensitive to the levels of `eta` than the rest of the methods. In the case of PCR and PLS, the difference in the effect of levels of `eta` is small.

In Figure \@ref(fig:pred-eff-plots) (right), we can see that the multicollinearity (controlled by `gamma`) has affected all the methods. However, envelope methods have better performance on low multicollinearity, as opposed to high multicollinearity, and PCR, PLS1 and PLS2 are robust for high multicollinearity. Despite handling high multicollinearity, these methods have higher prediction error in both cases of multicollinearity than the envelope methods.

(ref:pred-eff-plot) Effect plot of some interactions of the multivariate linear model of prediction error

```{r pred-eff-plots, fig.width=7, out.width='100%', fig.cap='(ref:pred-eff-plot)', fig.asp = 0.6}
thm <- theme(plot.title = element_blank(),
             plot.subtitle = element_blank(),
             legend.position = "top",
             axis.title = element_blank())
plt1 <- eff_df("eta:relpos:Method", pred_mdl) %>%
  eff_plot3(reorder = TRUE, labeller = label_both) +
  theme_grey(base_family = "mono") +
  thm
plt2 <- eff_df("relpos:gamma:Method", pred_mdl) %>%
  eff_plot3(reorder = TRUE, labeller = label_both) +
  theme_grey(base_family = "mono") +
  thm
plt <- gridExtra::arrangeGrob(plt1, plt2, ncol = 2,
                       bottom="Methods", padding = unit(0.04, 'npc'),
                       left = "Fitted Prediction Error")
grid::grid.newpage()
grid::grid.draw(plt)
```


## Effect Analysis of Component Model

(ref:comp-eff-plot) Effect plot of some interactions of the multivariate linear model of the number of components to get minimum prediction error


```{r comp-eff-plots, fig.width=7, out.width='100%', fig.cap='(ref:comp-eff-plot)', fig.asp = 0.6, fig.pos="!htb"}
thm <- theme(plot.title = element_blank(),
             plot.subtitle = element_blank(),
             legend.position = "top",
             ## axis.text.x = element_text(angle = 45, hjust = 1),
             axis.title = element_blank())
plt1 <- eff_df("eta:relpos:Method", comp_mdl) %>%
  eff_plot3(reorder = TRUE, labeller = label_both) +
  theme_grey(base_family = "mono") +
  thm
plt2 <- eff_df("relpos:gamma:Method", comp_mdl) %>%
  eff_plot3(reorder = TRUE, labeller = label_both) +
  theme_grey(base_family = "mono") +
  thm
plt <- gridExtra::arrangeGrob(plt1, plt2, ncol = 2,
                       bottom="Methods", padding = unit(0.04, 'npc'),
                       left = "Fitted Number of Components")
grid::grid.newpage()
grid::grid.draw(plt)
```

Unlike for prediction errors, Figure \@ref(fig:comp-eff-plots) (left) shows that the number of components used by the methods to obtain minimum prediction error is less affected by the levels of `eta`. All methods appear to use on average more components when eta increases. Envelope methods are able to obtain minimum prediction error by using components ranging from 1 to 3 in both the cases of `relpos`. This value is much higher in the case of PCR as its prediction is based only on the principal components of the predictor matrix. The number of components used by this method ranges from 3 to 5 when relevant components are at positions `r unique(opts$relpos)[1]` and 5 to 8 when relevant components are at positions  `r unique(opts$relpos)[2]`.

When relevant components are at position 5, 6, 7, 8, the eigenvalues of relevant predictors becomes smaller and responses are relatively difficult to predict. This becomes more critical for high multicollinearity cases. Figure \@ref(fig:comp-eff-plots) (right) shows that the envelope methods are less influenced by the level of `relpos` and are particularly better in achieving minimum prediction error using a fewer number of components than other methods.
