---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Examples

In addition to the analysis with the simulated data, the following two examples explore the prediction performance of the methods using real datasets. Since both examples have wide predictor matrices, principal components explaining 97.5% of the variation in them are used for envelope methods. The coefficients were transformed back after the estimation.

## Raman spectra analysis of contents of polyunsaturated fatty acids (PUFA)

```{r ex1-source-script}
commandArgs <- function(...) c("Raman-PUFA", 15, 2)
source("scripts/06-example.r")
```

This dataset contains `r sum(Dataset$train)` training samples and `r sum(!Dataset$train)` test samples of fatty acid information expressed as: a) percentage of total sample weight and b) percentage of total fat content. The dataset is borrowed from @naes2013multi where more information can be found. The samples were analysed using Raman spectroscopy from which `r ncol(Dataset$X)` wavelength variables were obtained as predictors. Raman spectroscopy provides detailed chemical information from minor components in food. The aim of this example is to compare how well the prediction methods that we have considered are able to predict the contents of PUFA using these Raman spectra.

(ref:ex1-relcomp-plot) (Left) Bar represents the eigenvalues corresponding to Raman Spectra. The points and line are the covariance between response and the principal components of Raman Spectra. All the values are normalized to scale from 0 to 1. (Middle) Cumulative sum of eigenvalues corresponding to predictors. (Right) Cumulative sum of eigenvalues corresponding to responses.

```{r ex1-cumulative-eigevalues, fig.asp = 0.4, fig.cap = "(ref:ex1-relcomp-plot)", fig.width=8}
relcomp_plot <- ex_plot_relcomp(relcomp_df, ncomp = NCOMP) +
  labs(x = NULL, title = NULL, subtitle = NULL, color = NULL)
plt_eigen <- function(data) {
  data %>% 
    ggplot(aes(x = ncomp, y = var_explained)) +
    geom_line() +
    geom_point(shape = 21, fill = "#efefef") +
    facet_grid(rows = vars(test_train),
               cols = vars(xy)) +
    labs(x = NULL, y = "Cummulative Eigenvalues") +
    scale_x_continuous(breaks = scales::pretty_breaks(n = 4))
}
plts <- eigen_df %>% 
  group_by(xy) %>% 
  group_split(keep = TRUE) %>% 
  map(plt_eigen)
plts[[2]] <- plts[[2]] + labs(y = NULL)
plts <- append(list(relcomp_plot), plts)
plts <- append(plts, list(
  nrow = 1,
  widths = c(3, 3, 2),
  bottom = "Number of Components"
))
plts[1:2] <- map(plts[1:2], function(p) {
  p + theme(strip.background.y = element_blank(),
        strip.text.y = element_blank()) +
    expand_limits(x = 0)
})
plt_grobs <- do.call(gridExtra::arrangeGrob, plts)
grid::grid.newpage()
grid::grid.draw(plt_grobs)
```

```{r}
ex1_design <- design_chr %>% rowid_to_column("Design") %>% 
  filter(p == 250, 
         relpos == "1, 2, 3, 4", 
         gamma == 0.9, 
         eta == 1.2) %>% 
  pluck("Design")
```

Figure \@ref(fig:ex1-cumulative-eigevalues) (left) shows that the first few predictor components are somewhat correlated with response variables. In addition the most variation in predictors are explained by less than five components (middle). Further, the response variables are highly correlated suggesting that a single latent dimension explains most of the variation (right). We may therefore also believe that the relevant latent space in the predictor matrix is of dimension one. This resembles the design `r ex1_design` (Figure \@ref(fig:design-plot)) from our simulation.

```{r ex1-minimum-prediction-error}
min_pred <- pred_error %>% 
  filter(Type == "test") %>% 
  group_by(Response, Method, Type) %>% 
  summarize(Component = Component[which.min(Error)],
            Error = min(Error)) %>% 
  mutate(label = paste0(round(Error, 2), " (", Component, ")")) %>% 
  group_by(Response) %>% 
  mutate(Color = ifelse(Error == min(Error), "red", "#484848"))
```
```{r}
mmin_err <- min_pred %>% filter(Error == min(Error))
```

```{r ex1-prediction-error, fig.asp = 0.6, fig.cap = "Prediction Error of different prediction methods using different number of components.", fig.pos="!htb"}
ggplot(pred_error, aes(Component, Error, color = Type)) +
  geom_line(aes(group = Type)) +
  geom_point(size = rel(0.5)) +
  facet_grid(Response ~ Method, scales = 'free') +
  scale_x_continuous(breaks = seq(0, NCOMP, 5)) +
  theme(legend.position = "bottom") +
  labs(x = "Number of Components",
       y = "Prediction Error (RMSEP)",
       color = NULL,
       title = "Prediction Error per Response",
       subtitle = "For each prediction method") +
  scale_color_discrete(labels = stringr::str_to_title) +
  geom_text(aes(label = paste0("Min RMSEP\n", label)), 
            data = min_pred,
            color = min_pred$Color,
            x = Inf, hjust = 1, 
            y = Inf, vjust = 1,
            family = "mono",
            size = rel(3))
```

Using a range of components from 1 to `r NCOMP`, a regression models were fitted using each of the methods. The fitted models were used to predict the test observation and the root mean squared error of prediction (RMSEP) was calculated. Figure \@ref(fig:ex1-prediction-error) shows that `r mmin_err[['Method']][1]` obtained minimum prediction error of `r mmin_err[['Error']][1]` using `r mmin_err[['Component']][1]` components in the case of response `r mmin_err[['Response']][1]` while `r mmin_err[['Method']][2]` obtained minimum prediction error of `r mmin_err[['Error']][2]` using `r mmin_err[['Component']][2]` components in the case of response `r mmin_err[['Response']][2]`. However the figure also shows that both envelope methods have reached to almost minimum predicton error in fewer number of components. This pattern is also visible in the simulation results (Figure \@ref(fig:comp-eff-plots)). 

## Example-2: NIR spectra of biscuit dough

The dataset consists of 700 wavelengths of NIR spectra (1100â€“2498 nm in steps of 2 nm) which were used as predictor variables. There are four response variables as the yield percentages of (a) fat, (b) sucrose, (c) flour and (d) water. The measurements were taken from 40 training observation of biscuit dough. A separate set with 32 samples which were created and measured on different occasions were used as test observations. The dataset is borrowed from @indahl2005twist where further information can be obtained.

```{r ex2-source-script}
commandArgs <- function(...) c("NIR_Dough", 15, 2)
source("scripts/06-example.r")
```

(ref:ex2-relcomp-plot) (Left) Bar represents the eigenvalues corresponding to NIR Spectra. The points and line are the covariance between response and the principal components of NIR Spectra. All the values are normalized to scale from 0 to 1. (Middle) Cumulative sum of eigenvalues corresponding to predictors. (Right) Cumulative sum of eigenvalues corresponding to responses.

```{r ex2-cumulative-eigevalues, fig.asp = 0.4, fig.cap = "(ref:ex2-relcomp-plot)", fig.width=8}
relcomp_plot <- ex_plot_relcomp(relcomp_df, ncomp = NCOMP) +
  labs(x = NULL, title = NULL, subtitle = NULL, color = NULL) +
  theme(legend.position = c(0.65, 0.8)) +
  guides(color = guide_legend(nrow = 2))
plt_eigen <- function(data) {
  data %>% 
    ggplot(aes(x = ncomp, y = var_explained)) +
    geom_line() +
    geom_point(shape = 21, fill = "#efefef") +
    facet_grid(rows = vars(test_train),
               cols = vars(xy)) +
    labs(x = NULL, y = "Cummulative Eigenvalues") +
    scale_x_continuous(breaks = scales::pretty_breaks(n = 4))
}
plts <- eigen_df %>% 
  group_by(xy) %>% 
  group_split(keep = TRUE) %>% 
  map(plt_eigen)
plts[[2]] <- plts[[2]] + labs(y = NULL)
plts <- append(list(relcomp_plot), plts)
plts <- append(plts, list(
  nrow = 1,
  widths = c(3, 3, 2),
  bottom = "Number of Components"
))
plts[1:2] <- map(plts[1:2], function(p) {
  p + theme(strip.background.y = element_blank(),
        strip.text.y = element_blank()) +
    expand_limits(x = 0)
})
plt_grobs <- do.call(gridExtra::arrangeGrob, plts)
grid::grid.newpage()
grid::grid.draw(plt_grobs)
```

```{r}
ex2_design <- design_chr %>% rowid_to_column("Design") %>% 
  filter(p == 250, 
         relpos == "1, 2, 3, 4", 
         gamma == 0.9, 
         eta == 1.2) %>% 
  pluck("Design")
```

Figure \@ref(fig:ex2-cumulative-eigevalues) (left) shows that the first predictor component has largest variance and also has large covariance with all response variables. The second component, however, has larger variance (middle) than the succeeding components but has small covaration with all the response which indicates that the component is less relevant for any of the responses. In addition, two response components have explained most of the variation in response variables (right). This structure is `r if(ex1_design == ex2_design) "also"` somewhat similar to Design `r ex2_design`, although it is uncertain whether the dimension of the relevant space in the response matrix is larger than one.

```{r ex2-minimum-prediction-error}
min_pred <- pred_error %>% 
  filter(Type == "test") %>% 
  group_by(Response, Method, Type) %>% 
  summarize(Component = Component[which.min(Error)],
            Error = min(Error)) %>% 
  mutate(label = paste0(round(Error, 2), " (", Component, ")")) %>% 
  group_by(Response) %>% 
  mutate(Color = ifelse(Error == min(Error), "red", "#484848"))
```
```{r}
mmin_err <- min_pred %>% filter(Error == min(Error))
```

```{r ex2-prediction-error, fig.asp = 0.8, fig.cap = "Prediction Error of different prediction methods using different number of components.", fig.pos="!htb"}
ggplot(pred_error, aes(Component, Error, color = Type)) +
  geom_line(aes(group = Type)) +
  geom_point(size = rel(0.5)) +
  facet_grid(Response ~ Method, scales = 'free') +
  scale_x_continuous(breaks = seq(0, NCOMP, 5)) +
  theme(legend.position = "bottom") +
  labs(x = "Number of Components",
       y = "Prediction Error (RMSEP)",
       color = NULL,
       title = "Prediction Error per Response",
       subtitle = "For each prediction method") +
  scale_color_discrete(labels = stringr::str_to_title) +
  geom_text(aes(label = paste0("Min RMSEP\n", label)), 
            data = min_pred,
            color = min_pred$Color,
            x = Inf, hjust = 1, 
            y = Inf, vjust = 1,
            family = "mono",
            size = rel(3))
```

Figure \@ref(fig:ex2-prediction-error) corresponding to \@ref(fig:ex1-prediction-error) shows the root mean squared error for both test and train prediction. Here four different methods have minimum test prediction error for the four responses. As the structure of the data is similar to the first example, the pattern in the prediction is also similar for all methods.

The prediction performance on the test data of the envelop methods appears to be more stable compared to the PCR and PLS methods. Furthermore, the envelope methods obtain good performance generally using fewer components, which is in accordance with Figure \@ref(fig:comp-pca-hist-mthd-gamma-relpos).
