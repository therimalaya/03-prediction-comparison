---
editor_options: 
  chunk_output_type: console
---
# Experimental Design #

This study compares prediction methods based on their prediction ability. Data with specific properties are simulated, some of which are easier to predict than others. These data are simulated using the R-package `simrel`, which is discussed in @saebo2015simrel and @Rimal2018. Here we will use four different factors to vary the property of the data: a) Number of predictors (`p`), b) Multicollinearity in predictor variables (`gamma`), c) Correlation in response variables (`eta`) and d) position of predictor components relevant for the response (`relpos`). Using two levels of `p`, `gamma` and `relpos` and four levels of `eta`, `r nrow(design)` set of distinct properties are designed for the simulation.

__Number of predictors:__
: In order to observe the performance of the methods on tall and wide predictor matrices, `r catvec(opts$p)` predictor variables are simulated. Parameter `p` controls this properties in the `simrel` function.

__Multicollinearity in predictor variables:__
: Highly collinear predictors can be explained completely by few components. The parameter `gamma` ($\gamma$) in `simrel` controls decline in the eigenvalues of the predictor variables as \@ref(eq:gamma).

    \begin{equation}
      \lambda_i = e^{-\gamma(i - 1)}, \gamma > 0 \text{ and } i = 1, 2, \ldots, p
      (\#eq:gamma)
    \end{equation}

  Here, $\lambda_i, i = 1, 2, \ldots p$ are eigenvalues of the predictor variables. Here we have used `r catvec(opts$gamma)` as different levels of `gamma`. The higher the value of gamma, the higher will be the correlation between predictors and vice versa.

__Correlation in response variables:__
: Correlation among response variables is a less explored area. Here we have tried to explore that part with `r length(opts$eta)` levels of correlation in the response variables. We have used the `eta` ($\eta$) parameter of `simrel` for controlling the decline in eigenvalues corresponding to the response variables as \@ref(eq:eta).

    \begin{equation}
      \kappa_i = e^{-\eta(i - 1)}, \eta > 0 \text{ and } j = 1, 2, \ldots, m
      (\#eq:eta)
    \end{equation}

  Here, $\kappa_i, i = 1, 2, \ldots m$ are the eigenvalues of the response variables and `m` is the number of response variables. Here we have used `r catvec(opts$eta)` as different levels of `eta`. The larger the value of eta, the larger will be the correlation between response variables and vice versa.

__Position of predictor components relevant to the response:__
: The principal components of the predictors are ordered. The first principal component captures most of the variation in the predictors. The second captures the most in the rest that is left by the first principal components and so on. In highly collinear predictors, the variation captured by the first few components is relatively high. However, if those components are not relevant for the response, prediction becomes difficult [@Helland1994b]. Here, two levels of the positions of these relevant components are used: `r catvec(sapply(opts$relpos, list2chr))`.


Further, a complete factorial design from the levels of the above given parameters gave us `r nrow(design)` designs. Each design is associated with a dataset having unique properties. Figure~\@ref(fig:design-plot), shows all the designs. For each design and prediction method, 50 datasets were simulated for replication. In total, there were $`r length(mthds)` \times `r nrow(design)` \times 50$, i.e. `r length(mthds) * nrow(design) * 50` dataset simulated.

```{r design-plot, fig.cap="Experimental Design of simulation parameters. Each point represents an unique data property.", echo = FALSE, fig.asp=0.5, fig.width=8}
design_chr %>%
    arrange(relpos, eta, p, gamma) %>%
    mutate(Design = row_number()) %>%
    ggplot(aes(eta, gamma)) +
    geom_point(shape=4) +
    ggrepel::geom_text_repel(aes(label = Design), nudge_x = 0.03) +
    facet_grid(p ~ relpos, labeller=label_both) +
    scale_y_reverse(breaks = opts$gamma) +
    scale_x_continuous(breaks = opts$eta) +
    theme_minimal(base_size=16) +
    theme(text=element_text(family="mono")) +
    coord_fixed(ratio=0.5)
```


__Common parameters:__
: Each dataset was simulated with $n = `r unique(opts$n)`$ number of observation and $m = `r unique(opts$m)`$ response variables. Further, the coefficient of determination corresponding to each response components in all the designs is set to `r catvec(unique(opts$R2))`. In addition, we have assumed that there is only `r num_vec[length(unique(design$ypos)[[1]])]` informative response component. Hence, the informative response component is rotated orthogonally together with `r num_vec[unique(opts$m) - length(unique(design$ypos)[[1]])]` uninformative response components to generate `r num_vec[unique(opts$m)]` response variables. This spread out the information in all simulated response variables. For further details on the simulation tool see [@Rimal2018].

An example of simulation parameters for the first design is as follows:

```{r sample_design, echo = TRUE, eval = FALSE}
simrel(
    n       = 100,                 ## Training samples
    p       = 20,                  ## Predictors
    m       = 4,                   ## Responses
    q       = 20,                  ## Relevant predictors
    relpos  = list(c(1, 2, 3, 4)), ## Relevant predictor components index
    eta     = 0,                   ## Decay factor of response eigenvalues
    gamma   = 0.2,                 ## Decay factor of predictor eigenvalues
    R2      = 0.8,                 ## Coefficient of determination
    ypos    = list(c(1, 2, 3, 4)),
    type    = "multivariate"
)
```


```{r cov-plot-1, fig.width = 9, out.width = "100%", fig.asp = 0.5, fig.cap="(left) Covariance structure of latent components. (right) Covariance structure of predictor and response", message=FALSE, eval=TRUE}
set.seed(010101)
sobj <- design %>%
    get_design(1) %>%
    simulate()
plt1 <- cov_plot(sobj, type = "relpos", facetting = FALSE) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5),
          panel.grid.minor = element_line(size = 0.2),
          panel.grid.major = element_blank())
plt2 <- cov_plot(sobj, type = "relpred", facetting = FALSE) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5),
          panel.grid.minor = element_line(size = 0.2),
          panel.grid.major = element_blank()) +
    scale_fill_brewer(palette = 'Set1',
                      labels = paste0("Y", unlist(sobj$ypos), collapse = ", "))
plt <- gridExtra::arrangeGrob(plt1, plt2, nrow = 1)
grid::grid.newpage()
grid::grid.draw(plt)
```


Figure \@ref(fig:cov-plot-1) shows the covariance structure of the data simulated with this design. The figure shows that the predictor components at position `r catvec(unlist(sobj$relpos))` are relevant for the first response component. After the rotation with orthogonal rotation matrix, all predictors are somewhat relevant for all response variables, fulfilling other desired properties like multicollinearity and coefficient of determination. For this same design, Figure \@ref(fig:est-cov-plot)(top left) shows that the predictor components `r catvec(unlist(sobj$relpos))` are relevant for the first response component. All other predictor components are irrelevant and all other response components are uninformative. However, due to orthogonal rotation of the informative response component together with uninformative response components, all response variables in the population have similar covariance with the relevant predictor components (Figure \@ref(fig:est-cov-plot)(top right)). The sample covariances between the predictors components and predictor variables with response variables are in Figure \@ref(fig:est-cov-plot) (bottom left) and (bottom right) respectively.


(ref:simrel-plot) Expected Scaled absolute covariance between predictor components and response components (top left). Expected Scaled absolute covariance between predictor components and response variables (top right). Sample scaled absolute covariance between predictor components and response variables (bottom left). Sample scaled absolute covariance between predictor variables and response variables (bottom right). The bar in the background are eigenvalues corresponding to each components in population (top plots) and in sample (bottom plots).

```{r est-cov-plot, fig.asp = 0.8, fig.width = 9, fig.cap = "(ref:simrel-plot)", warnings=FALSE, message=FALSE}
set.seed(010101) # design-method-replication
sobj <- design %>%
  get_design(1) %>%
  simulate()
breakx <- function(x) floor(seq(min(x), max(x), 2))
title_common <- function(title) {
  ggtitle(NULL, title)
}
thm_common <- theme(
  legend.position = c(0.99, 0.99),
  legend.direction = "horizontal",
  legend.justification = c(1, 1))
guid_common <- guides(color = guide_legend(title.position = "top"))
labs_common <- labs(y = NULL)
plt1 <- ggsimrelplot(sobj, which = 2, use_population = TRUE) +
  thm_common + guid_common + labs_common +
  title_common("Between predictor components and response components.") +
  scale_x_continuous(breaks = breakx)
plt2 <- ggsimrelplot(sobj, which = 3, use_population = TRUE) +
  thm_common + guid_common + labs_common +
  title_common("Between predictor components and response variables.") +
  scale_x_continuous(breaks = breakx)
plt3 <- ggsimrelplot(sobj, which = 3, use_population = FALSE) +
  title_common("Between predictor components and response variables.") +
  scale_x_continuous(breaks = breakx) +
  thm_common + guid_common + labs_common
plt4 <- ggsimrelplot(sobj, which = 4, use_population = FALSE) +
  title_common("Between predictor variables and response variables.") +
  scale_x_continuous(breaks = breakx) +
  thm_common + guid_common + labs_common
plt12 <- gridExtra::arrangeGrob(
  plt1, plt2, ncol = 2,
  top = "Scaled absolute population covariance")
plt34 <- gridExtra::arrangeGrob(
  plt3, plt4, ncol = 2,
  top = "Scaled absolute sample covariance"
)
plt <- gridExtra::arrangeGrob(plt12, plt34, ncol = 1, left = "Absolute Scaled Covariance")
grid::grid.newpage()
grid::grid.draw(plt)
```


The discussion here is made on the first design. A similar discussion can be made on all 32 designs where each of the design holds the properties of the data they simulate. These data are used by the prediction methods discussed in previous section. Each prediction methods are given independent dataset simulated in order to give them equal opportunity to understand the dynamics in the data.

## Basis of comparison

This study focuses mainly on the prediction performance of the methods and emphasis specifically on the interaction between the properties of the data, controlled by the simulation parameters, and the prediction methods. The prediction performance is measured by the average of prediction error that a method can give using arbitrary number of components and number of components used to give the minimum prediction error. Let us define, 

\begin{equation}
\mathcal{PE}_j = \frac{1}{\sigma_{y_j|x}^2}\left[\left(\boldsymbol{\beta}_j - \boldsymbol{\hat{\beta}_j}\right)^t\boldsymbol{\Sigma}_{xx}\left(\boldsymbol{\beta}_j - \boldsymbol{\hat{\beta}_j}\right)\right] + 1
(\#eq:pred-error)
\end{equation}
as a prediction error for a given design, method, replication and number of components, where, $\boldsymbol{\Sigma}_{xx}$ is the true covariance matrix of predictor and $\sigma_{y_j\mid x}$ is the true model error obtained from simulation of response $j = 1, \ldots m$. \highlight{Here prediction error is scaled by the true model error to remove its effect on prediction error.} (\alert{Need better and smart reason (sentence).}).

A dataset using \@ref(eq:pred-error) is obtained which contains five factors for simulation parameters, prediction methods, number of components, replications and prediction error for `r num_vec[unique(opts$m)]` responses. The prediction error is computed using 0 to 10 predictor components for each 50 replicates using \@ref(eq:pred-error). Thus there are `r nrow(design)` (design) $\times$ `r length(mthds)` (methods) $\times$ 11 (number of components) $\times$ 50 (replications), i.e. `r nrow(design) * length(mthds) * 11 * 50` observations. Here the variables `Y1` to `Y4` corresponds to prediction error of respective response variables.

```{r data-prep}
pred_dta <- design_chr %>%
  select_if(function(x) n_distinct(x) > 1) %>%
  mutate(Design = as.character(1:n())) %>%
  mutate_at(vars(p, gamma, relpos, eta), as.factor) %>%
  right_join(pred_error, by = "Design") %>%
  mutate_if(is.character, as.factor) %>%
  mutate_at("p", as.factor) %>%
  mutate(Response = paste0("Y", Response))
pred_spread_df <- pred_dta %>%
  as.data.frame() %>%
  select(-Design, -q) %>%
  spread(Response, Pred_Error)
min_comp_stk <- pred_dta %>%
  group_by(p, relpos, eta, gamma, Method, Tuning_Param, Response) %>%
  summarize(Pred_Error = mean(Pred_Error)) %>%
  group_by(p, relpos, eta, gamma, Method, Response) %>%
  summarize(Tuning_Param = Tuning_Param[which.min(Pred_Error)])
pred_min <- pred_dta %>% 
  select(-Design, -q) %>% 
  semi_join(min_comp_stk, by = c(
    "p", "relpos", "eta", "gamma", "Method", 
    "Tuning_Param", "Response"
  )) %>% select(-Tuning_Param) %>% 
  spread(Response, Pred_Error)
comp_min <- pred_dta %>% 
  group_by(p, relpos, eta, gamma, Method, Replication, Response) %>% 
  summarize(Tuning_Param = Tuning_Param[which.min(Pred_Error)]) %>% 
  spread(Response, Tuning_Param)
```


Since we will focus our discussion on the minimum prediction error that a method can obtain and the number of components they use to get minimum prediciton error in each replicate, the dataset discussed above is summarized to construct following two smaller datasets. Let us call them _Error Dataset_ and _Component Dataset_.

_Error Dataset_:
: For each prediction method, design and response, an average prediction error is computed over all replicates for each components. Next, a component that results in the minumum of this average prediction error is selected, i.e.,
  \begin{equation}
  nc_\circ = \operatorname*{argmin}_{nc}\left[\frac{1}{50}\sum_{i=1}^{50}{\mathcal{PE}_{ij}}\right]
  (\#eq:min-pred)
  \end{equation}
: where, $nc$ is the number of components and $\mathcal{PE}_{ij}$ is prediction error computed using \@ref(eq:pred-error) for response $j$ and replication $i$.

: Using the component $nc_\circ$, the prediction error for all 50 replicates are used to construct the _Error Dataset_.

_Component Dataset_: 
: Components that gives the minimum prediction error in each replication is used as _Component Dataset_, i.e.,
  \begin{equation}
  nc_j = \operatorname*{argmin}_{nc}\left[\mathcal{PE}_{j}\right]
  (\#eq:min-comp)
  \end{equation}
  Here $nc_i$ is the number of component that gives minimum prediction error for $j^\text{th}$ response for each replication.
