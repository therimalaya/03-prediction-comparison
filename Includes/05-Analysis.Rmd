# Statistical Analysis

```{r knitr_setup}
options(knitr.kable.NA = '')
docs_format <- ifelse(knitr::is_latex_output(), "latex", "html")
print_manova <- function(tbl, format = docs_format, level = 0.05, ...){
  signif_idx <- which(tbl[, ncol(tbl)] <= level)
  knitr::kable(
    x = tbl, digits = 3, booktabs = TRUE,
    longtable = TRUE, format = format,
    escape = FALSE, linesep = "", ...) %>%
    kableExtra::kable_styling(latex_options = c("repeat_header")) %>%
    kableExtra::column_spec(1:7, monospace = TRUE) %>%
    kableExtra::row_spec(signif_idx, color = "red")
}
```


The datasets discussed in previous section a) _error dataset_ and b) _component dataset_ are used on a multivariate analysis of variance. Let us call them _error model_ and _component model_ respectively. The models are fitted with the third order interaction of simulation parameters (`p`, `gamma`, `eta` and `relpos`) and `Methods` as in \@ref(eq:expanded-model).

\begin{equation}
\mathbf{y}_{abcdef} = \boldsymbol{\mu} + (\texttt{p}_a + \texttt{gamma}_b + \texttt{eta}_c + \texttt{relpos}_d + \texttt{Methods}_e)^3 + \boldsymbol{\varepsilon}_{abcdef}
(\#eq:expanded-model)
\end{equation}

where, $\mathbf{y}_{abcdef}$ is a vector of prediction error for factors,

- $\texttt{p}_a =$ `r catvec(opts$p)`
- $\texttt{gamma}_b=$ `r catvec(opts$gamma)`
- $\texttt{eta}_c=$ `r catvec(opts$eta)`
- $\texttt{relpos}_d=$ `r catvec(opts$relpos)`
- $\texttt{Methods}_e=$ `r catvec(map_chr(mthds, ~paste0("\\texttt{", .x, "}")))`


```{r manova-model}
## Full Prediction Model
pred_mdl <- lm(
  formula = cbind(Y1, Y2, Y3, Y4) ~ (p + gamma + eta + relpos + Method) ^ 3,
  data = pred_min)

## Full Component Model
comp_mdl <- lm(
  formula = cbind(Y1, Y2, Y3, Y4) ~ (p + gamma + eta + relpos + Method) ^ 3,
  data = comp_min)

## Anova for Full Prediction Model
pred_aov <- anova(pred_mdl) %>%
  as.data.frame() %>%
  rownames_to_column('Factors') %>%
  as_tibble()

## Anova for Full Component Model
comp_aov <- anova(comp_mdl) %>%
  as.data.frame() %>%
  rownames_to_column('Factors') %>%
  as_tibble()

## Joining both tables
aov_df <- bind_rows(list(Pred = pred_aov, Comp = comp_aov), .id = "Type")
```


(ref:manova-plot) Pillai Statistic and F-value for the MANOVA model. The bar represents the F-value and the text labels are Pillai Statistic for corresponding factor.

```{r manova-plot, fig.width=8, out.width='100%', fig.asp=0.5, fig.cap="(ref:manova-plot)"}
model_labels <- c(
  Comp = "Model: Number of Components",
  Pred = "Model: Prediction Error"
)
aov_df %>%
  filter(!(Factors %in% c('Residuals', '(Intercept)'))) %>%
  select(Model = Type, Factors, Pillai, Fvalue = `approx F`, Pvalue = `Pr(>F)`) %>%
  mutate(Pvalue = ifelse(Pvalue < 0.05, "<0.05", ">=0.05")) %>% 
  ggplot(aes(reorder(Factors, log1p(Fvalue)), log1p(Fvalue), fill = Pvalue)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = round(Pillai, 2)), family = 'mono', angle = 90, hjust = "inward") +
  facet_grid(cols = vars(Model), scales = 'free_y', 
             labeller = labeller(Model = model_labels)) +
  theme_grey(base_family = "mono") +
  theme(legend.position = c(0.2, 0.9),
        legend.direction = 'horizontal',
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(x = NULL, y = "log1p(Value)") +
  scale_y_continuous(trans = "log1p", breaks = scales::pretty_breaks(n=6))
```


Figure \@ref(fig:manova-plot) (left) shows the result from _component model_ and the figure \@ref(fig:manova-plot) (right) shows the result from _error model_. The figure shows that all main effects except `p` are significant and has large effect on _component model_ as well as _error model_.

In addition, the position of relevant components have largest effect on _error model_. In case of _component model_, multicollinearity also have large effect in addition to the position of relevant components. However based on Pillai trace statistic, `Method` has the largest effect on both of the models. Further, the interactions `p:gamma` and `eta:relpos:Method` has significant effect on the _error model_ but not in the _component model_. However, all of these interactions have small pillai statistic. 

Further, in the case of _component model_ interaction effects `gamma:eta:Method`, `p:Method` and `gamma:eta:relpos` are significant but not in the case of _error model_. Similar to previous point, they too have small pillai statistic. In the case of _error model_, the interaction effect of `eta:relpos:Method` which is particularly interesting to see that the methods performed differently for different cases of collinearity in response and collinearity in predictors.

Following section will continue on identifying the effect of different levels of factors in the case of these interactions.

## Effect Analysis

_Error Model_:

Figure \@ref(fig:pred-eff-plots) (left) shows clear difference of `eta` for a given `relpos`. The plot also shows a clear difference in effect of methods on prediction error. Figure \@ref(fig:pred-eff-plots) (right) shows effect of `gamma` for a given `method` and `eta`. It shows that these methods gives low prediction error is high multicollinear situations. 

```{r pred-eff-plots, fig.width=7, out.width='100%', fig.cap='Effect plot of some interactions of the multivariate linear model', fig.asp = 0.6}
thm <- theme(plot.title = element_blank(),
             plot.subtitle = element_blank(),
             legend.position = "bottom",
             axis.title = element_blank())
plt1 <- eff_df("eta:relpos:Method", pred_mdl) %>% 
  eff_plot3(reorder = TRUE, labeller = label_both) +
  theme_grey(base_family = "mono") +
  thm
plt2 <- eff_df("gamma:eta:Method", pred_mdl) %>% 
  eff_plot3(reorder = TRUE, labeller = label_both) +
  theme_grey(base_family = "mono") +
  thm
plt <- gridExtra::arrangeGrob(plt1, plt2, ncol = 2, 
                       bottom="Method", padding = unit(0.04, 'npc'),
                       left = "Fitted Prediction Error")
grid::grid.newpage()
grid::grid.draw(plt)
```


_Component Model_:

Figure \@ref(fig:comp-eff-plots) (left) shows that `xenv` has used minimum number of components followed by `senv` methods than others in order to get their minimum prediction error. The same figure also suggest that the minimum number of components used by `PLS1`, `PLS2` and `PCR` vary and has high effect of `eta`. The `senv` model which consider both X and Y correlation structure while estimating regression coefficients has smallest variation of number of components used for different `eta` parameters.

Figure \@ref(fig:comp-eff-plots) (right) shows that in case of low multicollinearity in the model `PLS` methods are used less number of components than `PCR`. This is expected since, `PLS` methods consider the covariance structure of predictor and response which `PCR` does not.


```{r comp-eff-plots, fig.width=7, out.width='100%', fig.cap='Effect plot of some interactions of the multivariate linear model', fig.asp = 0.6}
thm <- theme(plot.title = element_blank(),
             plot.subtitle = element_blank(),
             legend.position = "bottom",
             axis.title = element_blank())
plt1 <- eff_df("eta:relpos:Method", comp_mdl) %>% 
  eff_plot3(reorder = TRUE, labeller = label_both) +
  theme_grey(base_family = "mono") +
  thm
plt2 <- eff_df("gamma:eta:Method", comp_mdl) %>% 
  eff_plot3(reorder = TRUE, labeller = label_both) +
  theme_grey(base_family = "mono") +
  thm
plt <- gridExtra::arrangeGrob(plt1, plt2, ncol = 2, 
                       bottom="Method", padding = unit(0.04, 'npc'),
                       left = "Fitted Prediction Error")
grid::grid.newpage()
grid::grid.draw(plt)
```


